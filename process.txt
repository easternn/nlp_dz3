6 Nov 21:00 Начал изучать статью.
В голове следующий план
6 Nov - Изучу статью
7 Nov - Реализую модель, опубликую на hugging face, протестирую на бенчмарке tinyMMLU необученную модель. Раздебажу все места.
8, 9 Nov - Обучение. Цель - добиться обученной немного модели. К 9 Nov планирую Получить все необходимое для получение ненулевой оценки.
Готовый пайплайн для проведения экспериментов
10, 11 Nov - Эксперименты. Буду пытаться улучшить качество модели на готовом пайплайне.

6 Nov 22:37 Изучил статью. Выводы: Я не понимаю какая в итоге архитектура у модели, как происходит обучение.
Думаю посмотреть лекции по NLP, чтобы
Понять какая архитектура у модели LLaMa верхне-уровнево и как она обучается и как ее использовать.
Насколько я понял модель на вход принимает текст и выдает текст. Причем этот текст видимо произвольный.
Есть смысл изучить как будет оцениваться качество модели.

6 Nov 22:48 Решил прочитать текст про то что-за бенчмарки вот здесь: https://medium.com/alan/benchmarking-large-language-models-1e1ab5b809ac
6 Nov 22:59 Прочитал начало статьи https://medium.com/alan/benchmarking-large-language-models-1e1ab5b809ac
Понял, что все бенчмарки классифицируются на static / live и ground truth / preferences.
MMLU - это набор вопросов с выбором правильного ответа из предложенных.

6 Nov 23:01 Решил научиться применять tinyMMLU в домашке.
6 Nov 23:02 Чтобы проэвалить модель нужно загрузить ее на huggingface. Можно попробовать загрузить пустышку на huggingface.

